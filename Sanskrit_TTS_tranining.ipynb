{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c56FdJKLvSZV",
        "outputId": "beaa7a79-d4b0-46f2-ebe1-6663f7a20488"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'vits'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 115 (delta 11), reused 20 (delta 6), pack-reused 84\u001b[K\n",
            "Receiving objects: 100% (115/115), 4.97 MiB | 6.14 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone 'https://github.com/AlvinKimata/vits'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R1yQgB9au2Yy",
        "outputId": "ccdd388e-5173-48ed-925b-d4751dc0b60b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.29.36)\n",
            "Requirement already satisfied: librosa==0.9.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.22.4)\n",
            "Requirement already satisfied: phonemizer in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.10.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.12.3)\n",
            "Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.13.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.14.0)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.3.6)\n",
            "Collecting jamo (from -r requirements.txt (line 11))\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Collecting pypinyin==0.44.0 (from -r requirements.txt (line 12))\n",
            "  Downloading pypinyin-0.44.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jieba==0.42.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.42.1)\n",
            "Collecting protobuf==3.19.0 (from -r requirements.txt (line 14))\n",
            "  Downloading protobuf-3.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cn2an==0.5.17 (from -r requirements.txt (line 15))\n",
            "  Downloading cn2an-0.5.17-py3-none-any.whl (18 kB)\n",
            "Collecting inflect==6.0.0 (from -r requirements.txt (line 16))\n",
            "  Downloading inflect-6.0.0-py3-none-any.whl (34 kB)\n",
            "Collecting eng_to_ipa==0.0.2 (from -r requirements.txt (line 17))\n",
            "  Downloading eng_to_ipa-0.0.2.tar.gz (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ko_pron==1.3 (from -r requirements.txt (line 18))\n",
            "  Downloading ko_pron-1.3-py3-none-any.whl (12 kB)\n",
            "Collecting indic_transliteration==2.3.37 (from -r requirements.txt (line 19))\n",
            "  Downloading indic_transliteration-2.3.37-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting num_thai==0.0.5 (from -r requirements.txt (line 20))\n",
            "  Downloading num_thai-0.0.5-py3-none-any.whl (4.8 kB)\n",
            "Collecting opencc==1.1.1 (from -r requirements.txt (line 21))\n",
            "  Downloading OpenCC-1.1.1-py2.py3-none-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (0.4.2)\n",
            "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1->-r requirements.txt (line 2)) (23.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0->-r requirements.txt (line 8)) (4.7.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0->-r requirements.txt (line 8)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0->-r requirements.txt (line 8)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0->-r requirements.txt (line 8)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0->-r requirements.txt (line 8)) (11.7.99)\n",
            "Requirement already satisfied: setuptools>=47.3.1 in /usr/local/lib/python3.10/dist-packages (from cn2an==0.5.17->-r requirements.txt (line 15)) (67.7.2)\n",
            "Collecting ruamel.yaml>=0.16.0 (from cn2an==0.5.17->-r requirements.txt (line 15))\n",
            "  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting proces>=0.1.0 (from cn2an==0.5.17->-r requirements.txt (line 15))\n",
            "  Downloading proces-0.1.6-py3-none-any.whl (249 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.4/249.4 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from inflect==6.0.0->-r requirements.txt (line 16)) (1.10.12)\n",
            "Collecting backports.functools-lru-cache (from indic_transliteration==2.3.37->-r requirements.txt (line 19))\n",
            "  Downloading backports.functools_lru_cache-1.6.6-py2.py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from indic_transliteration==2.3.37->-r requirements.txt (line 19)) (2022.10.31)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from indic_transliteration==2.3.37->-r requirements.txt (line 19)) (0.9.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from indic_transliteration==2.3.37->-r requirements.txt (line 19)) (0.10.2)\n",
            "Collecting roman (from indic_transliteration==2.3.37->-r requirements.txt (line 19))\n",
            "  Downloading roman-4.1-py3-none-any.whl (5.5 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->-r requirements.txt (line 8)) (0.41.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 3)) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: segments in /usr/local/lib/python3.10/dist-packages (from phonemizer->-r requirements.txt (line 5)) (2.2.1)\n",
            "Requirement already satisfied: attrs>=18.1 in /usr/local/lib/python3.10/dist-packages (from phonemizer->-r requirements.txt (line 5)) (23.1.0)\n",
            "Requirement already satisfied: dlinfo in /usr/local/lib/python3.10/dist-packages (from phonemizer->-r requirements.txt (line 5)) (1.2.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.56.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.4.4)\n",
            "INFO: pip is looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorboard (from -r requirements.txt (line 7))\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorboard-2.12.1-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard->-r requirements.txt (line 7))\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tensorboard (from -r requirements.txt (line 7))\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (2.27.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard->-r requirements.txt (line 7))\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard->-r requirements.txt (line 7))\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 7)) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 7)) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 7)) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 7)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.45.1->librosa==0.9.1->-r requirements.txt (line 2)) (0.39.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.9.1->-r requirements.txt (line 2)) (1.4.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 7)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 7)) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 7)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 7)) (3.4)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.16.0->cn2an==0.5.17->-r requirements.txt (line 15))\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.1->-r requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa==0.9.1->-r requirements.txt (line 2)) (1.15.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 7)) (2.1.3)\n",
            "Requirement already satisfied: clldutils>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from segments->phonemizer->-r requirements.txt (line 5)) (3.19.0)\n",
            "Requirement already satisfied: csvw>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from segments->phonemizer->-r requirements.txt (line 5)) (3.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer->indic_transliteration==2.3.37->-r requirements.txt (line 19)) (8.1.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.1->-r requirements.txt (line 2)) (2.21)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer->-r requirements.txt (line 5)) (0.9.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer->-r requirements.txt (line 5)) (6.7.0)\n",
            "Requirement already satisfied: pylatexenc in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer->-r requirements.txt (line 5)) (4.9.3)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5)) (2.12.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5)) (4.3.3)\n",
            "Requirement already satisfied: language-tags in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5)) (6.3.2)\n",
            "Requirement already satisfied: rfc3986<2 in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5)) (1.5.0)\n",
            "Requirement already satisfied: uritemplate>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5)) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 7)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 7)) (3.2.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer->-r requirements.txt (line 5)) (0.19.3)\n",
            "Building wheels for collected packages: eng_to_ipa\n",
            "  Building wheel for eng_to_ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eng_to_ipa: filename=eng_to_ipa-0.0.2-py3-none-any.whl size=2822605 sha256=86805bf29eb35891ee5332aa33a05f4e22e8acee8a66f0ac8c0d5f05a00807be\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/ab/07/fe6722f710d8ef8bd0ccb4eb689ef96f5552f3fc0c80c1aa9c\n",
            "Successfully built eng_to_ipa\n",
            "Installing collected packages: tensorboard-plugin-wit, opencc, ko_pron, jamo, eng_to_ipa, tensorboard-data-server, ruamel.yaml.clib, roman, pypinyin, protobuf, num_thai, backports.functools-lru-cache, ruamel.yaml, inflect, indic_transliteration, proces, google-auth-oauthlib, tensorboard, cn2an\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.1\n",
            "    Uninstalling tensorboard-data-server-0.7.1:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: inflect\n",
            "    Found existing installation: inflect 6.0.5\n",
            "    Uninstalling inflect-6.0.5:\n",
            "      Successfully uninstalled inflect-6.0.5\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
            "google-cloud-bigquery 3.10.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.22.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
            "google-cloud-functions 1.13.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
            "google-cloud-language 2.9.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
            "google-cloud-translate 3.11.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
            "googleapis-common-protos 1.59.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
            "grpc-google-iam-v1 0.12.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.19.0 which is incompatible.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.0 which is incompatible.\n",
            "tensorflow 2.12.0 requires tensorboard<2.13,>=2.12, but you have tensorboard 2.11.2 which is incompatible.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.0 which is incompatible.\n",
            "tensorflow-hub 0.14.0 requires protobuf>=3.19.6, but you have protobuf 3.19.0 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backports.functools-lru-cache-1.6.6 cn2an-0.5.17 eng_to_ipa-0.0.2 google-auth-oauthlib-0.4.6 indic_transliteration-2.3.37 inflect-6.0.0 jamo-0.4.1 ko_pron-1.3 num_thai-0.0.5 opencc-1.1.1 proces-0.1.6 protobuf-3.19.0 pypinyin-0.44.0 roman-4.1 ruamel.yaml-0.17.32 ruamel.yaml.clib-0.2.7 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlZsjTWzwW1P",
        "outputId": "8bc3ef5a-9723-4d8a-b01a-fda89a9f3bd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: cd: vits: No such file or directory\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "espeak is already the newest version (1.48.15+dfsg-3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 9 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "!cd vits && pip install -r requirements.txt\n",
        "!apt-get install espeak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1QlnQD61kN0",
        "outputId": "a3e2111e-b752-44c1-c6f6-7ba8f30fcb18"
      },
      "outputs": [],
      "source": [
        "!mkdir ../root/.kaggle/\n",
        "!echo '{\"username\":\"username\",\"key\":\"api_key\"}' >> /root/.kaggle/kaggle.json\n",
        "!chmod 400 ../root/.kaggle/kaggle.json  #Read-only\n",
        "!cat ../root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi3Z9PUz1iYN",
        "outputId": "c0a398f7-0be3-49f4-f8e6-e43b2186b9db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading sanskrit-wav.zip to /content\n",
            "100% 7.17G/7.17G [01:05<00:00, 99.3MB/s]\n",
            "100% 7.17G/7.17G [01:05<00:00, 117MB/s] \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d kimatadebonair/sanskrit-wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZonBnEwV1tPb"
      },
      "outputs": [],
      "source": [
        "!mkdir '/content/vits/inputs'\n",
        "!unzip '/content/sanskrit-wav.zip' -d '/content/vits/inputs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Sx1Gh4fkvrvx"
      },
      "outputs": [],
      "source": [
        "!mv '/content/vits/inputs' '/content/vits/sanskrit'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk-nL0z9xeFs",
        "outputId": "86830bf5-3091-4eaf-f590-70701769d784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/vits\n",
            "Compiling core.pyx because it changed.\n",
            "[1/1] Cythonizing core.pyx\n",
            "/usr/local/lib/python3.10/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/vits/monotonic_align/core.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n"
          ]
        }
      ],
      "source": [
        "%cd vits\n",
        "!cd monotonic_align && mkdir monotonic_align\n",
        "# Cython-version Monotonoic Alignment Search\n",
        "!cd monotonic_align && python setup.py build_ext --inplace\n",
        "\n",
        "# Preprocessing (g2p) for your own datasets. Preprocessed phonemes for LJ Speech and VCTK have been already provided.\n",
        "# python preprocess.py --text_index 1 --filelists filelists/ljs_audio_text_train_filelist.txt filelists/ljs_audio_text_val_filelist.txt filelists/ljs_audio_text_test_filelist.txt\n",
        "# python preprocess.py --text_index 2 --filelists filelists/vctk_audio_sid_text_train_filelist.txt filelists/vctk_audio_sid_text_val_filelist.txt filelists/vctk_audio_sid_text_test_filelist.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OeU6gBqxfWs",
        "outputId": "ec243a62-0504-4a5c-d8c7-c33766086263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoKzwacj2pj_",
        "outputId": "cab283e3-2c73-4b6a-983d-459e16267761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/vits\n",
            "INFO:sanskrit_base:{'train': {'log_interval': 200, 'eval_interval': 1000, 'seed': 1234, 'epochs': 10000, 'learning_rate': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 32, 'fp16_run': True, 'lr_decay': 0.999875, 'segment_size': 8192, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0}, 'data': {'training_files': 'filelists/sanskrit_train_filelist.txt.cleaned', 'validation_files': 'filelists/sanskrit_val_filelist.txt.cleaned', 'text_cleaners': ['sanskrit_cleaners'], 'max_wav_value': 32768.0, 'sampling_rate': 16000, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': None, 'add_blank': True, 'n_speakers': 0, 'cleaned_text': False}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [8, 8, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4], 'n_layers_q': 3, 'use_spectral_norm': False, 'gin_channels': 256}, 'speakers': ['Male 1', 'Male 2', 'Male 3', 'Male 4 (Malayalam)', 'Male 5', 'Male 6', 'Male 7', 'Male 8 (Kannada)', 'Female 1 (Tamil)', 'Male 9 (Kannada)', 'Female 2 (Marathi)', 'Female 3 (Marathi)', 'Female 4 (Marathi)', 'Female 5 (Telugu)', 'Female 6 (Telugu)', 'Male 10 (Kannada)', 'Male 11 (Kannada)', 'Male 12', 'Male 13', 'Male 14', 'Male 15', 'Female 7', 'Male 16 (Malayalam)', 'Male 17 (Tamil)', 'Male 18 (Hindi)', 'Male 19 (Telugu)', 'Male 20 (Hindi)'], 'symbols': ['_', '।', 'ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'ळ', 'व', 'श', 'ष', 'स', 'ह', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'े', 'ै', 'ो', 'ौ', '्', 'ॠ', 'ॢ', ' '], 'model_dir': './logs/sanskrit_base'}\n",
            "WARNING:sanskrit_base:git hash values are different. 6cb09990(saved) != 783cd848(current)\n",
            "2023-07-29 13:23:51.643667: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
            "./logs/sanskrit_base/G_0.pth\n",
            "INFO:sanskrit_base:Loaded checkpoint './logs/sanskrit_base/G_0.pth' (iteration 1)\n",
            "./logs/sanskrit_base/D_0.pth\n",
            "INFO:sanskrit_base:Loaded checkpoint './logs/sanskrit_base/D_0.pth' (iteration 1)\n",
            "/content/vits/mel_processing.py:78: FutureWarning: Pass sr=16000, n_fft=1024, n_mels=80, fmin=0.0, fmax=None as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mel = librosa_mel_fn(sampling_rate, n_fft, num_mels, fmin, fmax)\n",
            "/content/vits/mel_processing.py:96: FutureWarning: Pass sr=16000, n_fft=1024, n_mels=80, fmin=0.0, fmax=None as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mel = librosa_mel_fn(sampling_rate, n_fft, num_mels, fmin, fmax)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:632: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:801.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:632: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at ../aten/src/ATen/EmptyTensor.cpp:31.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:197: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
            "grad.sizes() = [1, 9, 96], strides() = [21984, 96, 1]\n",
            "bucket_view.sizes() = [1, 9, 96], strides() = [864, 96, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:325.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "INFO:sanskrit_base:Train Epoch: 1 [0%]\n",
            "INFO:sanskrit_base:[5.91162109375, 5.909283638000488, 0.538963794708252, 102.00376892089844, 2.1228535175323486, 181.65924072265625, 0, 0.0002]\n",
            "DEBUG:matplotlib:matplotlib data path: /usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data\n",
            "DEBUG:matplotlib:CONFIGDIR=/root/.config/matplotlib\n",
            "DEBUG:matplotlib:interactive is False\n",
            "DEBUG:matplotlib:platform is linux\n",
            "INFO:sanskrit_base:Saving model and optimizer state at iteration 1 to ./logs/sanskrit_base/G_0.pth\n",
            "INFO:sanskrit_base:Saving model and optimizer state at iteration 1 to ./logs/sanskrit_base/D_0.pth\n"
          ]
        }
      ],
      "source": [
        "# LJ Speech\n",
        "%cd /content/vits/\n",
        "# !python train.py -c configs/sanskrit_base.json -m sanskrit_base\n",
        "\n",
        "# Multiple speakers\n",
        "!python train_ms.py -c configs/sanskrit_base.json -m sanskrit_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvWQzTze6tmG",
        "outputId": "d0686f87-e2bb-4b88-f478-e470462fc1fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2G\t/content/vits/logs\n"
          ]
        }
      ],
      "source": [
        "!du -sh '/content/vits/logs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-219jq25eFv",
        "outputId": "5e97bd89-a6d8-4f81-8e94-3b2b9d0d7008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/vits/logs/ (stored 0%)\n",
            "  adding: content/vits/logs/ljs_base/ (stored 0%)\n",
            "  adding: content/vits/logs/ljs_base/D_2000.pth (deflated 7%)\n",
            "  adding: content/vits/logs/ljs_base/train.log (deflated 63%)\n",
            "  adding: content/vits/logs/ljs_base/events.out.tfevents.1690617670.d3eb0b92d055.3158.0 (deflated 3%)\n",
            "  adding: content/vits/logs/ljs_base/eval/ (stored 0%)\n",
            "  adding: content/vits/logs/ljs_base/eval/events.out.tfevents.1690617670.d3eb0b92d055.3158.1 (deflated 15%)\n",
            "  adding: content/vits/logs/ljs_base/G_0.pth (deflated 9%)\n",
            "  adding: content/vits/logs/ljs_base/G_2000.pth (deflated 8%)\n",
            "  adding: content/vits/logs/ljs_base/D_1000.pth (deflated 7%)\n",
            "  adding: content/vits/logs/ljs_base/D_0.pth (deflated 8%)\n",
            "  adding: content/vits/logs/ljs_base/config.json (deflated 59%)\n",
            "  adding: content/vits/logs/ljs_base/G_1000.pth (deflated 8%)\n",
            "  adding: content/vits/logs/ljs_base/githash (deflated 3%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r '/content/tts-logs.zip' '/content/vits/logs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHnWQvxG-PA6",
        "outputId": "0c7ab6ec-475c-4fc8-996f-93fe87902eaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgil7K3x-P4n"
      },
      "outputs": [],
      "source": [
        "!cp '/content/tts-logs.zip' '/content/drive/MyDrive/Datasets'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuH3U4Ed-s4d",
        "outputId": "660ad5d3-e02b-4252-9425-fbd46ae97ff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "json_data  sanskrit.zip  swahili_pretrained.h5\ttts-logs.zip\n"
          ]
        }
      ],
      "source": [
        "!ls '/content/drive/MyDrive/Datasets'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6P42ytD-1XV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
